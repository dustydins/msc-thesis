% Chapter Template

\chapter{Background \& Literature Review}\label{Chapter2}

\lhead{Chapter 2. \emph{Background \& Literature Review}} % Change X to a consecutive number; this is for the header on each page - perhaps a shortened title

This chapter will provide a background understanding to the important concepts that are required by this thesis, and explore the
current trends within \Gls{aiv} research.
This includes an introduction to formal verification, both within deterministic and non-deterministic systems; an overview of the
current state of \Gls{nn} and deep learning research, and the programming paradigms used for their development; and finally an 
investigation into the Go programming language infrastructure and the feasibility of using it for verifying \glspl{nn}.

%----------------------------------------------------------------------------------------
%	SECTION NEURAL NETWORKS
%----------------------------------------------------------------------------------------
\section{Neural Networks \& Deep Learning}
This section aims to clarify the concepts of \glspl{nn} and deep learning, as well as
to show the successes and failures of the field, and to demonstrate the need for
formal approaches for developing such algorithms.

\subsection{Overview}

\glspl{nn} are learning algorithms based on a loose analogy of how the
human brain functions. They consist of nodes, or neurons
(\textit{see Fig.~\ref{fig:an}}), which act as functions that output a
nonlinear combination of weighted inputs and a bias~\citep{Dreyfus2005}.
Learning is achieved by adjusting the weights on the connections between
nodes, which are analogous to synapses and neurons in nature~\citep{Sammut2010}.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.5\textwidth]{media/literature/artificial-neuron1.png}
        \rule{35em}{0.5pt}
        \caption[Example of an artifcial neuron]{\textbf{Artificial Neuron} -- a nonlinear bounded function $y = f(x_{1}, x_{2},\ldots,x_{n};w_{2},\ldots,w_{n})$ where the ${x_{i}}$ are the input values and the  ${w_{i}}$ are the weights of the neuron~\citep{Dreyfus2005}.}\label{fig:an}
\end{figure}


A weight is assigned to each of a neuron's inputs. They are the co-efficients of a neuron's equation and therefore reflect the importance of individual inputs. A bias is a constant value assigned to each neuron. They are used to shift a neuron's activation function output in a positive or negative direction~\citep{Malik2019weights}.

A \Gls{nn} is made up of a series of layers; an input layer,
a number of hidden layers, and an output layer. Each layer is
made up of a set of neurons, where each neuron is fully connected
to all neurons in the previous layer. Each neuron within a single layer
does not share connections with, and operates completely independently from one another~\citep{cs231n}.


Using the case of \Gls{cv} as an example, 
the input layer of a \Gls{nn} consists of
neurons encoding the values of image pixels (RGB or greyscale intensities).
The encoding is typically achieved by passing the raw input 
value through an activation function which outputs a normalised value. 
Often, activation functions in modern \Glspl{nn} output non-linearities, 
an example is to use a Sigmoid Function which maps an input to a value between 0 and 1 
(\textit{see Fig.~\ref{fig:activation} \textit{left}})~\citep{Nielsen2015}.

However a more common activation function found in current \gls{nn} models for \gls{cv} is the \gls{relu}.
It also adds non-linearity to the output, however it maps the input to a value
within the range of $0 \text{ and } \infty$ (\textit{see Fig.~\ref{fig:activation} \textit{right}})~\citep{Malik2019activation}.

\begin{figure}[H]
    \includegraphics[width=0.5\textwidth]{media/literature/sigmoid.png}
    \includegraphics[width=0.5\textwidth]{media/literature/relu.png}
    \rule{35em}{0.5pt}
    \caption[Examples of Activation Functions]{\textit{Left}: The Sigmoid Function is one type of activation function. `A bounded, differentiable, real function that is defined for all real input values and has a non negative derivative at each point'~\citep{Han1995}. \textit{Right}: An example of a \Gls{relu} activation function transforming $x$ to a value between $0 \text{ and } \infty$~\citep{Malik2019activation}.}\label{fig:activation}
\end{figure}


The output layer of a \gls{cv} classification network contains neurons representing the class
scores of the task (\textit{see Fig.~\ref{fig:nn}}). For example, in a \gls{nn} attempting to classify handwritten
digits, the output layer would contain 10 neurons, representing the digits 0 - 9.
If the first neuron fires, i.e.\ has an output $\approx l,$ this will indicate that the
network is confident the handwritten digit is 0, and so on~\citep{Nielsen2015}.

\begin{figure}[H]
\includegraphics[width=1\textwidth]{media/literature/handwrittenDigitNN.png}
    \rule{35em}{0.5pt}
\caption[Example of a Neural Network]{Neural Network. Example of a \Gls{nn} to
classify handwritten digits. The input is a single vector of 28x28 pixels, i.e. 784 neurons, and outputs
10 neurons representing digits 0-9~\citep{Nielsen2015}.}\label{fig:nn}
\end{figure}

% TODO: explain what deep learning is in context of  nns
\glspl{nn} with a single hidden layer are able to approximate functions that contain any 
continuous mapping from one finite space to another, whereas with no hidden layers a \gls{nn}
model would only be able to represent linear functions or decision boundaries~\citep{hornik1991}.

\begin{figure}[H]
\includegraphics[width=1\textwidth]{media/literature/deep-boundary.png}
    \rule{35em}{0.5pt}
    \caption[Complex decision boundary from deep neural network]{\textbf{Complex Decision Boundary} -- Example of a decision boundary made capable by deep learning~\citep{sapkota2020}}\label{fig:dnn-decision}
\end{figure}

\glspl{nn} are especially powerful when additional hidden layers are
added to a network's architecture. By doing so, a model can not only approximate continuous functions
to a high accuracy with less computational cost, but it can also represent complex composite 
functions~\citep{sapkota2020}. An example of the complex decision boundaries that are possible from
\glspl{nn} with more than one hidden layer can be seen in \textit{Fig.~\ref{fig:dnn-decision}}.

\glspl{nn} with two or more hidden layers fall under the category of deep learning, and are often referred to as
\Glspl{dnn} or \Glspl{mlp}. This subset
of \gls{ml} has become increasingly powerful with the rise of powerful variations of \glspl{dnn}, namely \Glspl{cnn} and \Glspl{rnn} in recent years
due to their successes within the field of \gls{cv}.
% TODO make this paragraph nicer (add refs etc)

\subsection{Gradient Descent \& Backpropagation}
% TODO: explain how nns can be trained using backpropagation
Training a \gls{nn} consists of iteratively adjusting the values of weights at
each neuron in order to minimise the model's output error. Although there
are many algorithms available for determining the optimum values of weights, a common approach
is by using some flavour of \Gls{gd} 
together with a technique for efficiently computing partial derivatives within a directed graph called \textit{backpropagation}.

There are three main variants of \gls{gd}; vanilla \gls{gd} or \Gls{bgd}, \Gls{sgd}, and \Gls{mbgd}.

\gls{bgd} computes the gradients of a cost function with regards to the weights within an entire training set.
The cost function can take many forms depending on the architecture of the \gls{nn} and the task it is concerned with,
however the main principle behind it is to map the different
values of each weight to a score which determines how well the model performs~\citep{shung2018}.

\begin{figure}[H]
\includegraphics[width=1\textwidth]{media/literature/gd-example.png}
    \rule{35em}{0.5pt}
    \caption[Example visualisation of gradient descent]{\textbf{Visualisation of \gls{gd} Search Space} -- An example of an \textit{ideal} search space, where the vertical $z$ axis shows the cost function $f(x, y)$, and $\vec{v}$ represents the resulting vector applied to the parameter in question~\citep{bendersky2016}.}\label{fig:gd-example}
\end{figure}

A search space can then be defined by plotting the output of a cost function against the values of the weights
it is concerned with, an example of such a search space with two weights can be seen in \textit{Fig.~\ref{fig:gd-example}}.
As the number of weights increases, the harder it becomes to visualise the contours of a multi-dimensional plane. 
\gls{bgd} then computes the directional derivative of this plane given a set of weight values, and uses this value
as a vector with a magnitude defined by a \textit{learning rate} hyper-parameter to update the weights of the network~\citep{ruder2017}.

\gls{sgd} attempts to reduce the number of 
computations during training by only performing updates
to weights for each training example instead of recomputing gradients for similar weights
at each iteration. By removing these redundant calculations, \gls{sgd} typically decreases the time taken
to converge to an optimum solution of weights. Additionally, due to the high variance of
each update, and so long as the learning rate is steadily decreased at each iteration, \gls{sgd} has an equal
chance at finding the global minimum than \gls{bgd}~\citep{ruder2017}.

\gls{mbgd} on the other hand, attempts to combine the benefits from \gls{bgd} and \gls{sgd} by 
performing an update for every mini-batch of $n$ training examples. Therefore, allowing for the precision of
\gls{bgd} with similar speeds as \gls{sgd}.

backpropagation is a computational technique commonly used within \gls{nn} training for calculating
partial derivatives used for \gls{gd} algorithms in linear time with respect 
to the number of weights being optimised. This is an important
step in order to train \glspl{nn} within a sensible timeframe, considering the potentially
high volume of weights that are needed for complex tasks. A more detailed 
investigation into this technique will be discussed later in this chapter (\textit{Section~\ref{section:paradigms}}).

\subsection{Vulnerabilities to Adversarial Attacks}

\glspl{nn} and \glspl{dnn} have been adopted and deployed within a wide
range of industry applications for tasks such as speech recognition or facial recognition, 
and have shown to perform adequately for many of these tasks. However, as mentioned in \textit{Chapter~\ref{Chapter1}}, \glspl{nn} have been shown to be
vulnerable to adversarial attacks. Specifically, by adding small, imperceptable changes
to the input features, can lead to abnormal behaviours such as missclassification in the output layer.

% 3 examples of adversarial attacks on nns (not Google's sticker one)
This observation was first discovered in 2014,
which found properties of \glspl{nn} that cause them to learn uninterpretable solutions that could have counter-intuitive properties when
imperceptable non-random pertubartions are made to a test input, known as \textit{adversarial examples}~\citep{szegedy2014}. 
Interestingly, these examples were shown to be robust, such that they have the same effect
across models with varying architectures, activation functions, or trained on different datasets altogether. A tentative
explanation for this phenomenon was to blame the non-linear nature of \glspl{nn}, and cases of poor generalisation on test data.

\begin{figure}[H]
\center
\includegraphics[width=0.9\textwidth]{media/literature/adversarial-example.png}
    \rule{35em}{0.5pt}
    \caption[Demonstration of the effects of adversarial examples]{\textbf{Effects of Adversarial Examples} -- A demonstration of the effects of adversarial examples; an input image of a panda with added noise causes the model to missclassify the image as a gibbon~\citep{goodfellow2015}.}\label{fig:adversarial-example}
\end{figure}

However in 2015, further attempts to explain \gls{nn} vulnerabilities to adversarial examples argued
that it was not the non-linear nature, but rather the linear behaviour of \glspl{nn} which is sufficient 
to cause adversarial examples~\citep{goodfellow2015}. This claim was supported by the authors' demonstration that
leveraging non-linear \gls{nn} families such as \Glspl{rbfn} can significantly reduce the vulnerabilities to adversarial examples.

\begin{figure}[H]
\center
\includegraphics[width=0.9\textwidth]{media/literature/stop-sign.jpg}
    \rule{35em}{0.5pt}
    \caption[Demonstration of the effects of adversarial examples in real world]{\textbf{Effects of Adversarial Examples in Real World} -- A demonstration of how adversarial examples can be used in real world situations to cause misclassification of stop signs~\citep{eykholt2018}.}\label{fig:stop-sign}
\end{figure}

Research in 2018 showed that adversarial examples can be 
used in real world situations in order to fool a \gls{dnn} used for street sign 
recognition within a self-driving car's navigation system by placing black and white stickers
on street signs (\textit{see Fig.~\ref{fig:stop-sign}})~\citep{eykholt2018}.

These vulnerabilities have demonstrated that \gls{nn} technology has yet to reach the level of
maturity necessary for applications in safety-critical systems, and have raised
concerns over the robustness of \glspl{nn} in general.


\subsection{Descrimination \& Neural Networks}

Aside from vulnerabilities caused by intrinsic properties of \glspl{nn}, there are
issues which stem from the data being used to train supervised models too. That is,
if the training data has inherent bias towards or against a specific class within the domain, the output 
of the model trained on that data will reflect these biases. Subsequently, when \glspl{nn} trained on this data are
used to aid decision making in areas which directly or indirectly affect people's lives, can
result in simulated descrimination of certain social groups.

Examples \ldots

why verification is needed/can help \ldots

% facial recognition

% sexist ai in hiring tasks

%

%----------------------------------------------------------------------------------------
%	SECTION Formal Verification
%----------------------------------------------------------------------------------------

\section{Formal Verification}

Formal verification is a mature and extensive discipline which has seen development in many areas 
of software engineering. As such, this section will attempt to provide a succinct 
overview of the ideas behind formal verification while keeping the focus on areas
related to this thesis.

\subsection{Background}


\subsection{Current Frameworks}

%----------------------------------------------------------------------------------------
%	SECTION Formal Verification AI
%----------------------------------------------------------------------------------------

\section{Formal Verification of AI}

This section will provide a more detailed investigation into the current research
undertaken within \gls{aiv}, with a focus on \glspl{nn} and deep learning tasks.

\subsection{Overview}

\subsection{Sapphire}


%----------------------------------------------------------------------------------------
%	SECTION PROGRAMMING PARADIGMS FOR ML
%----------------------------------------------------------------------------------------
\section{Programming Paradigms for Machine Learning}\label{section:paradigms}

\subsection{Computational Graphs}
\subsection{Auto Differentiability}

%----------------------------------------------------------------------------------------
%	SECTION PROGRAMMING The Go Programming Language
%----------------------------------------------------------------------------------------
\section{The Go Programming Language}

\subsection{Brief History}
\subsection{Go for ML}
\subsection{Go for Formal Verification}

%----------------------------------------------------------------------------------------
%	SECTION CONCLUSIONS
%----------------------------------------------------------------------------------------
\section{Conclusions}
