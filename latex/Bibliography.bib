@MISC{pypl,
  author = {Carbonelle, Pierre},
  title = {PYPL PopularitY of Programming Language index},
  url = {https://pypl.github.io/PYPL.html},
  year = {2021},
  organization = {Github.io}
}

@misc{redmonk,
    title={The RedMonk Programming Language Rankings: January 2021},
    url={https://redmonk.com/sogrady/2021/03/01/language-rankings-1-21/},
    journal={tecosystems},
    author={O'Grady, Stephen},
    year={2021},
    month={Mar}}

@misc{opensource,
author = {Benson, Deepu},
title = {10 most popular programming languages - Open Source For You},
howpublished = {\url{https://www.opensourceforu.com/2017/03/most-popular-programming-languages/}},
month = {Mar},
year = {2017},
note = {(Accessed on 03/09/2021)}
}

@misc{ieee-spectrum,
author = {Diakopoulous, N. and Bagavandas, M. and Singh, G. and Kulkarni, P.},
title = {Interactive: The Top Programming Languages 2020 - IEEE Spectrum},
howpublished = {\url{https://spectrum.ieee.org/static/interactive-the-top-programming-languages-2020}},
month = {Aug},
year = {2020},
note = {(Accessed on 03/09/2021)}
}

@misc{tiobe,
author = {Jansen, P.},
title = {index | TIOBE - The Software Quality Company},
howpublished = {\url{https://www.tiobe.com/tiobe-index/?20210304%20%20%20%20%20%20}},
month = {Mar},
year = {2021},
note = {(Accessed on 03/09/2021)}
}

@misc{whatispython,
author = {Python},
title = {What is Python? Executive Summary | Python.org},
howpublished = {\url{https://www.python.org/doc/essays/blurb/}},
month = {Mar},
year = {2021},
note = {(Accessed on 03/10/2021)}
}

@article{amodei,
  author    = {Dario Amodei and
               Chris Olah and
               Jacob Steinhardt and
               Paul F. Christiano and
               John Schulman and
               Dan Man{\'{e}}},
  title     = {Concrete Problems in {AI} Safety},
  journal   = {CoRR},
  volume    = {abs/1606.06565},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.06565},
  archivePrefix = {arXiv},
  eprint    = {1606.06565},
  timestamp = {Mon, 13 Aug 2018 16:48:59 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/AmodeiOSCSM16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{pereira,
AUTHOR = {Pereira, Ana and Thomas, Carsten},
TITLE = {Challenges of Machine Learning Applied to Safety-Critical Cyber-Physical Systems},
JOURNAL = {Machine Learning and Knowledge Extraction},
VOLUME = {2},
YEAR = {2020},
NUMBER = {4},
PAGES = {579--602},
URL = {https://www.mdpi.com/2504-4990/2/4/31},
ISSN = {2504-4990},
ABSTRACT = {Machine Learning (ML) is increasingly applied for the control of safety-critical Cyber-Physical Systems (CPS) in application areas that cannot easily be mastered with traditional control approaches, such as autonomous driving. As a consequence, the safety of machine learning became a focus area for research in recent years. Despite very considerable advances in selected areas related to machine learning safety, shortcomings were identified on holistic approaches that take an end-to-end view on the risks associated to the engineering of ML-based control systems and their certification. Applying a classic technique of safety engineering, our paper provides a comprehensive and methodological analysis of the safety hazards that could be introduced along the ML lifecycle, and could compromise the safe operation of ML-based CPS. Identified hazards are illustrated and explained using a real-world application scenario&mdash;an autonomous shop-floor transportation vehicle. The comprehensive analysis presented in this paper is intended as a basis for future holistic approaches for safety engineering of ML-based CPS in safety-critical applications, and aims to support the focus on research onto safety hazards that are not yet adequately addressed.},
DOI = {10.3390/make2040031}
}

@inbook{bishop,
author = {Bishop, Christopher},
year = {2006},
month = {01},
pages = {140-155},
title = {Pattern Recognition and Machine Learning},
volume = {16},
journal = {Journal of Electronic Imaging},
doi = {10.1117/1.2819119}
}

@article{goodfellow,
author = {Goodfellow, Ian and Shlens, Jonathon and Szegedy, Christian},
year = {2014},
month = {12},
pages = {},
title = {Explaining and Harnessing Adversarial Examples},
journal = {arXiv 1412.6572}
}

@misc{brown2018,
      title={Adversarial Patch}, 
      author={Tom B. Brown and Dandelion Mané and Aurko Roy and Martín Abadi and Justin Gilmer},
      year={2018},
      eprint={1712.09665},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{zhang2019,
      title={Machine Learning Testing: Survey, Landscapes and Horizons}, 
      author={Jie M. Zhang and Mark Harman and Lei Ma and Yang Liu},
      year={2019},
      eprint={1906.10742},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{molnar2019,
  title      = {Interpretable Machine Learning},
  author     = {Christoph Molnar},
  note       = {\url{https://christophm.github.io/interpretable-ml-book/}},
  year       = {2019},
  subtitle   = {A Guide for Making Black Box Models Explainable}
}

@inproceedings{ammann2008,
  title={Introduction to Software Testing},
  author={P. Ammann and A. J. Offutt},
  year={2008}
}

@misc{russell2016,
      title={Research Priorities for Robust and Beneficial Artificial Intelligence}, 
      author={Stuart Russell and Daniel Dewey and Max Tegmark},
      year={2016},
      eprint={1602.03506},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

TY  - JOUR
AU  - Lomuscio, Alessio
AU  - Qu, Hongyang
AU  - Raimondi, Franco
PY  - 2017
DA  - 2017/02/01
TI  - MCMAS: an open-source model checker for the verification of multi-agent systems
JO  - International Journal on Software Tools for Technology Transfer
SP  - 9
EP  - 30
VL  - 19
IS  - 1
AB  - We present MCMAS, a model checker for the verification of multi-agent systems. MCMAS supports efficient symbolic techniques for the verification of multi-agent systems against specifications representing temporal, epistemic and strategic properties. We present the underlying semantics of the specification language supported and the algorithms implemented in MCMAS, including its fairness and counterexample generation features. We provide a detailed description of the implementation. We illustrate its use by discussing a number of examples and evaluate its performance by comparing it against other model checkers for multi-agent systems on a common case study.
SN  - 1433-2787
UR  - https://doi.org/10.1007/s10009-015-0378-x
DO  - 10.1007/s10009-015-0378-x
ID  - Lomuscio2017
ER  - 
@misc{lomuscio2017,
    title={MCMAS: an open-source model checker for the verification of multi-agent systems},
    author={Lomuscio, Alessio and Qu, Hongyang and Raimondi, Franco},
    year={2017},
    journal={International Journal on Software Tools for Technology Transfer},
    url={\url{https://doi.org/10.1007/s10009-015-0378-x}}
}

@misc{lomuscio2017approach,
      title={An approach to reachability analysis for feed-forward ReLU neural networks}, 
      author={Alessio Lomuscio and Lalit Maganti},
      year={2017},
      eprint={1706.07351},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@article{kouvaros2016,
author = {Kouvaros, Panagiotis and Lomuscio, Alessio},
title = {Parameterised Verification for Multi-Agent Systems},
year = {2016},
issue_date = {May 2016},
publisher = {Elsevier Science Publishers Ltd.},
address = {GBR},
volume = {234},
number = {C},
issn = {0004-3702},
url = {https://doi.org/10.1016/j.artint.2016.01.008},
doi = {10.1016/j.artint.2016.01.008},
abstract = {We study the problem of verifying role-based multi-agent systems, where the number of components cannot be determined at design time. We give a semantics that captures parameterised, generic multi-agent systems and identify three notable classes that represent different ways in which the agents may interact among themselves and with the environment. While the verification problem is undecidable in general we put forward cutoff procedures for the classes identified. The methodology is based on the existence of a notion of simulation between the templates for the agents and the template for the environment in the system. We show that the cutoff identification procedures as well as the general algorithms that we propose are sound; for one class we show the decidability of the verification problem and present a complete cutoff procedure. We report experimental results obtained on MCMAS-P, a novel model checker implementing the parameterised model checking methodologies here devised.},
journal = {Artif. Intell.},
month = may,
pages = {152–189},
numpages = {38},
keywords = {Cutoffs, Validation, Parameterised verification, Multi-agent systems}
}

@article{polak1979,
  title={An exercise in automatic program verification},
  author={Polak, Wolfgang},
  journal={IEEE Transactions on Software Engineering},
  number={5},
  pages={453--458},
  year={1979},
  publisher={IEEE}
}

@InProceedings{boyer1990,
author="Boyer, Robert S.
and Moore, J. Strother",
editor="Stickel, Mark E.",
title="A theorem prover for a computational logic",
booktitle="10th International Conference on Automated Deduction",
year="1990",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--15",
abstract="We briefly review a mechanical theorem-prover for a logic of recursive functions over finitely generated objects including the integers, ordered pairs, and symbols. The prover, known both as NQTHM and as the Boyer-Moore prover, contains a mechanized principle of induction and implementations of linear resolution, rewriting, and arithmetic decision procedures. We describe some applications of the prover, including a proof of the correct implementation of a higher level language on a microprocessor defined at the gate level. We also describe the ongoing project of recoding the entire prover as an applicative function within its own logic.",
isbn="978-3-540-47171-4"
}

@misc{kokke2020,
    title={A library for translating TensorFlow models to Z3},
    year={2020},
    author={Kokke, Wen},
    url={https://github.com/wenkokke/sapphire},
}

@InProceedings{guaspari1993,
author="Guaspari, David
and Marceau, Carla
and Polak, Wolfgang",
editor="Martin, Ursula
and Wing, Jeannette M.",
title="Formal Verification of Ada Programs",
booktitle="First International Workshop on Larch",
year="1993",
publisher="Springer London",
address="London",
pages="104--141",
abstract="This paper describes the Penelope verification editor and its formal basis. Penelope is a prototype system for the interactive development and verification of programs that are written in a rich subset of sequential Ada.",
isbn="978-1-4471-3558-6"
}

@misc{innes2017,
    title={On Machine Learning and Programming Languages},
    url={https://julialang.org/blog/2017/12/ml-pl/#fnref:tf},
    journal={The Julia Programming Language},
    author={Innes, Mike and Barber, David and Besard, Tim and Bradbury, James and Churavy, Valentin and Danisch, Simon and Edelman, Alan and Karpinski, Stefan and Malmaud, Jon and Revels, Jarrett and et al.},
    year={2017},
    month={Dec}
} 
 @misc{golang2020, 
 title={Golang Machine Learning Libraries},
 url={https://golangdocs.com/golang-machine-learning-libraries},
 journal={GoLang Docs},
 author={GoLang},
 year={2020},
 month={Aug}
} 

 @misc{chew2016, 
 title={Gorgonia},
 url={https://blog.chewxy.com/2016/09/19/gorgonia/},
 author={Chew, Xuanyi},
 year={2016},
 month={Sep}
} 

@inproceedings{demoura2008,
author = {De Moura, Leonardo and Bj\o{}rner, Nikolaj},
title = {Z3: An Efficient SMT Solver},
year = {2008},
isbn = {3540787992},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Satisfiability Modulo Theories (SMT) problem is a decision problem for logical first order formulas with respect to combinations of background theories such as: arithmetic, bit-vectors, arrays, and uninterpreted functions. Z3 is a new and efficient SMT Solver freely available from Microsoft Research. It is used in various software verification and analysis applications.},
booktitle = {Proceedings of the Theory and Practice of Software, 14th International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
pages = {337–340},
numpages = {4},
location = {Budapest, Hungary},
series = {TACAS'08/ETAPS'08}
}

@article{fisher2017,
author = {Fisher, Kathleen and Launchbury, John and Richards, Raymond},
year = {2017},
month = {10},
pages = {20150401},
title = {The HACMS program: Using formal methods to eliminate exploitable bugs},
volume = {375},
journal = {Philosophical Transactions of The Royal Society A Mathematical Physical and Engineering Sciences},
doi = {10.1098/rsta.2015.0401}
}

@article{shaikhha2019,
author = {Shaikhha, Amir and Fitzgibbon, Andrew and Vytiniotis, Dimitrios and Peyton Jones, Simon},
title = {Efficient Differentiable Programming in a Functional Array-Processing Language},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {ICFP},
url = {https://doi.org/10.1145/3341701},
doi = {10.1145/3341701},
abstract = {We present a system for the automatic differentiation (AD) of a higher-order functional array-processing language. The core functional language underlying this system simultaneously supports both source-to-source forward-mode AD and global optimisations such as loop transformations. In combination, gradient computation with forward-mode AD can be as efficient as reverse mode, and that the Jacobian matrices required for numerical algorithms such as Gauss-Newton and Levenberg-Marquardt can be efficiently computed.},
journal = {Proc. ACM Program. Lang.},
month = jul,
articleno = {97},
numpages = {30},
keywords = {Linear Algebra, Optimising Compilers, Differentiable Programming, Loop Fusion, Code Motion}
}

@Inbook{Sammut2010,
editor="Sammut, Claude
and Webb, Geoffrey I.",
title="Neural Networks",
bookTitle="Encyclopedia of Machine Learning",
year="2010",
publisher="Springer US",
address="Boston, MA",
pages="716--716",
isbn="978-0-387-30164-8",
doi="10.1007/978-0-387-30164-8_586",
url="https://doi.org/10.1007/978-0-387-30164-8_586"
}

@Inbook{Dreyfus2005,
author="Dreyfus, G.",
title="Neural Networks: An Overview",
bookTitle="Neural Networks: Methodology and Applications",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--83",
isbn="978-3-540-28847-3",
doi="10.1007/3-540-28847-3_1",
url="https://doi.org/10.1007/3-540-28847-3_1"
}

@Inbook{Nielsen2015,
title="Neural Networks and Deep Learning",
author="Nielsen, Michael. A.",
year="2015",
publisher="Determination press"
}

@InProceedings{Han1995,
author="Han, Jun
and Moraga, Claudio",
editor="Mira, Jos{\'e}
and Sandoval, Francisco",
title="The influence of the sigmoid function parameters on the speed of backpropagation learning",
booktitle="From Natural to Artificial Neural Computation",
year="1995",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="195--201",
abstract="Sigmoid function is the most commonly known function used in feed forward neural networks because of its nonlinearity and the computational simplicity of its derivative. In this paper we discuss a variant sigmoid function with three parameters that denote the dynamic range, symmetry and slope of the function respectively. We illustrate how these parameters influence the speed of backpropagation learning and introduce a hybrid sigmoidal network with different parameter configuration in different layers. By regulating and modifying the sigmoid function parameter configuration in different layers the error signal problem, oscillation problem and asymmetrical input problem can be reduced. To compare the learning capabilities and the learning rate of the hybrid sigmoidal networks with the conventional networks we have tested the two-spirals benchmark that is known to be a very difficult task for backpropagation and their relatives.",
isbn="978-3-540-49288-7"
}

@misc{cs231n,
  author="{Stanford Vision and Leaning Lab}",
  title = {CS231n Convolutional Neural Networks for Visual Recognition},
  howpublished = {\url{http://cs231n.github.io/convolutional-networks/}},
  note = {accessed: 04.11.2019},
  year = {2012}
}

@misc{Malik2019activation, title={Neural Network Activation Function Types}, howpublished={\url{https://medium.com/fintechexplained/neural-network-activation-function-types-a85963035196}}, author={Malik, Farhad}, year={2019}, month={Jul}, 
note={accessed: 06.11.2019}}

@misc{Malik2019weights, title={Neural Networks Bias And Weights}, howpublished={\url{https://medium.com/fintechexplained/neural-networks-bias-and-weights-10b53e6285da}}, journal={Medium}, author={Malik, Farhad}, year={2019}, month={May},
note={accessed: 06.11.2019}}

@article{hornik1991,
author = {Hornik, Kurt},
title = {Approximation Capabilities of Multilayer Feedforward Networks},
year = {1991},
issue_date = {1991},
publisher = {Elsevier Science Ltd.},
address = {GBR},
volume = {4},
number = {2},
issn = {0893-6080},
url = {https://doi.org/10.1016/0893-6080(91)90009-T},
doi = {10.1016/0893-6080(91)90009-T},
journal = {Neural Netw.},
month = mar,
pages = {251–257},
numpages = {7}
}

@misc{sapkota2020,
    description = {A Journey From Perceptron to Deep Neural Networks in a sequential fashion. Start with Perceptron, move to Logistic Regression, Single Layer Neural Network, Multilayer Perceptron (1 hidden layer) and finally to Deep Neural Network. Understand the algorithms sequentially along with visualization and math.},
    author = {Sapkota, Suman},
    title = {Perceptron to Deep-Neural-Network | Rough AI Blog},
    howpublished = {\url{https://tsumansapkota.github.io/algorithm/2020/06/06/Perceptron-to-DeepNeuralNets/}},
    note = {Accessed: 2021-04-05 05:32:32},
    year = {2020},
    month = june
}
@misc{bendersky2016,
    author = {Bendersky, Eli},
    year = {2016},
    month = Aug,
    title = {Understanding gradient descent - Eli Bendersky's website},
    howpublished = \url\{https://eli.thegreenplace.net/2016/understanding-gradient-descent/},
    note = {Accessed: 2021-04-06 11:58:11}
}

@misc{shung2018,
    author = {Shung, Koo Ping},
    year = {2018},
    month = Apr,
    title = {Gradient Descent: Simply Explained? | by Koo Ping Shung | Towards Data Science},
    howpublished = \url\{https://towardsdatascience.com/gradient-descent-simply-explained-1d2baa65c757},
    note = {Accessed: 2021-04-06 02:23:39}
}

@misc{ruder2017,
      title={An overview of gradient descent optimization algorithms}, 
      author={Sebastian Ruder},
      year={2017},
      eprint={1609.04747},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{szegedy2014,
      title={Intriguing properties of neural networks}, 
      author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
      year={2014},
      eprint={1312.6199},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{goodfellow2015,
      title={Explaining and Harnessing Adversarial Examples}, 
      author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
      year={2015},
      eprint={1412.6572},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@INPROCEEDINGS{eykholt2018,
  author={K. {Eykholt} and I. {Evtimov} and E. {Fernandes} and B. {Li} and A. {Rahmati} and C. {Xiao} and A. {Prakash} and T. {Kohno} and D. {Song}},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={Robust Physical-World Attacks on Deep Learning Visual Classification}, 
  year={2018},
  volume={},
  number={},
  pages={1625-1634},
  doi={10.1109/CVPR.2018.00175}}

  @misc{burns2019,
      title={Women also Snowboard: Overcoming Bias in Captioning Models}, 
      author={Kaylee Burns and Lisa Anne Hendricks and Kate Saenko and Trevor Darrell and Anna Rohrbach},
      year={2019},
      eprint={1803.09797},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{kim2019,
      title={Learning Not to Learn: Training Deep Neural Networks with Biased Data}, 
      author={Byungju Kim and Hyunwoo Kim and Kyungsu Kim and Sungjin Kim and Junmo Kim},
      year={2019},
      eprint={1812.10352},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{ryu2018,
      title={InclusiveFaceNet: Improving Face Attribute Detection with Race and Gender Diversity}, 
      author={Hee Jung Ryu and Hartwig Adam and Margaret Mitchell},
      year={2018},
      eprint={1712.00193},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
    
@incollection{seligman2015,
title = {Chapter 1 - Formal verification: From dreams to reality},
editor = {Erik Seligman and Tom Schubert and M V Achutha Kiran Kumar},
booktitle = {Formal Verification},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {1-22},
year = {2015},
isbn = {978-0-12-800727-3},
doi = {https://doi.org/10.1016/B978-0-12-800727-3.00001-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128007273000010},
author = {Erik Seligman and Tom Schubert and M V Achutha Kiran Kumar},
keywords = {Assertions, Formal Verification (FEV), Formal Equivalence Verification (FEV), Formal Property Verification (FPV), Satisfiability, Undecidability, Complexity, NP-complete}
}

@incollection{grout2008,
title = {CHAPTER 1 - Introduction to Programmable Logic},
editor = {Ian Grout},
booktitle = {Digital Systems Design with FPGAs and CPLDs},
publisher = {Newnes},
address = {Burlington},
pages = {1-41},
year = {2008},
isbn = {978-0-7506-8397-5},
doi = {https://doi.org/10.1016/B978-0-7506-8397-5.00001-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780750683975000015},
author = {Ian Grout}
}

@article{smith2011,
author = {Smith, Robin},
year = {2011},
month = {01},
pages = {417-424},
title = {Aristotle. Prior Analytics Book 1},
volume = {31},
journal = {Ancient Philosophy},
doi = {10.5840/ancientphil201131231}
}

@book{boole2009, place={Cambridge}, series={Cambridge Library Collection - Mathematics}, title={An Investigation of the Laws of Thought: On Which Are Founded the Mathematical Theories of Logic and Probabilities}, DOI={10.1017/CBO9780511693090}, publisher={Cambridge University Press}, author={Boole, George}, year={2009}, collection={Cambridge Library Collection - Mathematics}}

@book{russell1937,
	publisher = {Routledge},
	author = {Bertrand Russell},
	year = {1937},
	title = {Principles of Mathematics}
}
@article{geuvers2009,
title = "Proof assistants : history, ideas and future",
abstract = "In this paper I will discuss the fundamental ideas behind proof assistants: What are they and what is a proof anyway? I give a short history of the main ideas, emphasizing the way they ensure the correctness of the mathematics formalized. I will also briefly discuss the places where proof assistants are used and how we envision their extended use in the future. While being an introduction into the world of proof assistants and the main issues behind them, this paper is also a position paper that pushes the further use of proof assistants. We believe that these systems will become the future of mathematics, where definitions, statements, computations and proofs are all available in a computerized form. An important application is and will be in computer supported modelling and verification of systems. But there is still a long road ahead and I will indicate what we believe is needed for the further proliferation of proof assistants. Keywords. Proof assistant; verification; logic; software correctness; formalized mathematics.",
author = "J.H. Geuvers",
year = "2009",
doi = "10.1007/s12046-009-0001-5",
language = "English",
volume = "34",
pages = "3--25",
journal = "Sadhana : Academy Proceedings in Engineering Sciences (Indian Academy of Sciences)",
issn = "0256-2499",
publisher = "Springer",
number = "1",
}

@book{clarke2018,
  title={Model Checking, second edition},
  author={Clarke, E.M. and Grumberg, O. and Kroening, D. and Peled, D. and Veith, H.},
  isbn={9780262349451},
  series={Cyber Physical Systems Series},
  url={https://books.google.co.uk/books?id=qJl8DwAAQBAJ},
  year={2018},
  publisher={MIT Press}
}

@inproceedings{zhang2019,
author = {Zhang, Chengyu and Su, Ting and Yan, Yichen and Zhang, Fuyuan and Pu, Geguang and Su, Zhendong},
title = {Finding and Understanding Bugs in Software Model Checkers},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3338932},
doi = {10.1145/3338906.3338932},
abstract = {Software Model Checking (SMC) is a well-known automatic program verification technique and frequently adopted for checking safety-critical software. Thus, the reliability of SMC tools themselves (i.e., software model checkers) is critical. However, little work exists on validating software model checkers, an important problem that this paper tackles by introducing a practical, automated fuzzing technique. For its simplicity and generality, we focus on control-flow reachability (e.g., whether or how many times a branch is reached) and address two specific challenges for effective fuzzing: oracle and scalability. Given a deterministic program, we (1) leverage its concrete executions to synthesize valid branch reachability properties (thus solving the oracle problem) and (2) fuse such individual properties into a single safety property (thus improving the scalability of fuzzing and reducing manual inspection). We have realized our approach as the MCFuzz tool and applied it to extensively test three state-of-the-art C software model checkers, CPAchecker, CBMC, and SeaHorn. MCFuzz has found 62 unique bugs in all three model checkers -- 58 have been confirmed, and 20 have been fixed. We have further analyzed and categorized these bugs (which are diverse), and summarized several lessons for building reliable and robust model checkers. Our testing effort has been well-appreciated by the model checker developers, and also led to improved tool usability and documentation.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {763–773},
numpages = {11},
keywords = {Fuzz Testing, Software Model Checking, Software Testing},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{akintunde2020,
author = {Akintunde, Michael E. and Botoeva, Elena and Kouvaros, Panagiotis and Lomuscio, Alessio},
title = {Formal Verification of Neural Agents in Non-Deterministic Environments},
year = {2020},
isbn = {9781450375184},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We introduce a model for agent-environment systems where the agents are implemented via feed-forward ReLU neural networks and the environment is non-deterministic. We study the verification problem of such systems against CTL properties. We show that verifying these systems against reachability properties is undecidable. We introduce a bounded fragment of CTL, show its usefulness in identifying shallow bugs in the system, and prove that the verification problem against specifications in bounded CTL is in coNEXPTIME and PSPACE-hard. We present a novel parallel algorithm for MILP-based verification of agent-environment systems, present an implementation, and report the experimental results obtained against a variant of the VerticalCAS use-case.},
booktitle = {Proceedings of the 19th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {25–33},
numpages = {9},
keywords = {neural systems, verification},
location = {Auckland, New Zealand},
series = {AAMAS '20}
}

@inproceedings{akintunde2018,
  title={Reachability Analysis for Neural Agent-Environment Systems.},
  author={Akintunde, Michael and Lomuscio, Alessio and Maganti, Lalit and Pirovano, Edoardo},
  booktitle={KR},
  pages={184--193},
  year={2018}
}


@InProceedings{katz2019,
author="Katz, Guy
and Huang, Derek A.
and Ibeling, Duligur
and Julian, Kyle
and Lazarus, Christopher
and Lim, Rachel
and Shah, Parth
and Thakoor, Shantanu
and Wu, Haoze
and Zelji{\'{c}}, Aleksandar
and Dill, David L.
and Kochenderfer, Mykel J.
and Barrett, Clark",
editor="Dillig, Isil
and Tasiran, Serdar",
title="The Marabou Framework for Verification and Analysis of Deep Neural Networks",
booktitle="Computer Aided Verification",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="443--452",
abstract="Deep neural networks are revolutionizing the way complex systems are designed. Consequently, there is a pressing need for tools and techniques for network analysis and certification. To help in addressing that need, we present Marabou, a framework for verifying deep neural networks. Marabou is an SMT-based tool that can answer queries about a network's properties by transforming these queries into constraint satisfaction problems. It can accommodate networks with different activation functions and topologies, and it performs high-level reasoning on the network that can curtail the search space and improve performance. It also supports parallel execution to further enhance scalability. Marabou accepts multiple input formats, including protocol buffer files generated by the popular TensorFlow framework for neural networks. We describe the system architecture and main components, evaluate the technique and discuss ongoing work.",
isbn="978-3-030-25540-4"
}

@inproceedings{pulina2010,
  title={An abstraction-refinement approach to verification of artificial neural networks},
  author={Pulina, Luca and Tacchella, Armando},
  booktitle={International Conference on Computer Aided Verification},
  pages={243--257},
  year={2010},
  organization={Springer}
}
@article{xiang2018,
  title={Output reachable set estimation and verification for multilayer neural networks},
  author={Xiang, Weiming and Tran, Hoang-Dung and Johnson, Taylor T},
  journal={IEEE transactions on neural networks and learning systems},
  volume={29},
  number={11},
  pages={5777--5783},
  year={2018},
  publisher={IEEE}
}
@misc{kouvaros2018,
      title={Formal Verification of CNN-based Perception Systems}, 
      author={Panagiotis Kouvaros and Alessio Lomuscio},
      year={2018},
      eprint={1811.11373},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{zhang2020,
title = "Verification of recurrent neural networks for cognitive tasks via reachability analysis",
abstract = "Recurrent Neural Networks (RNNs) are one of the most successful neural network architectures that deal with temporal sequences, e.g., speech and text recognition. Recently, RNNs have been shown to be useful in cognitive neuroscience as a model of decision-making. RNNs can be trained to solve the same behavioral tasks performed by humans and other animals in decision-making experiments, allowing for a direct comparison between networks and experimental subjects. Analysis of RNNs is expected to be a simpler problem than the analysis of neural activity. However, in practice, reasoning about an RNN's behaviour is a challenging problem. In this work, we take an approach based on formal verification for the analysis of RNNs. We make two main contributions. First, we consider the cognitive domain and formally define a set of useful properties to analyse for a popular experimental task. Second, we employ and adapt wellknown verification techniques for reachability analysis to our focus domain, i.e., polytope propagation, invariant detection, and counter-example-guided abstraction refinement. Our experiments show that our techniques can effectively solve classes of benchmark problems that are challenging for state-of-the-art verification tools.",
author = "Hongce Zhang and Maxwell Shinn and Aarti Gupta and Arie Gurfinkel and Nham Le and Nina Narodytska",
note = "Publisher Copyright: {\textcopyright} 2020 The authors and IOS Press. Copyright: Copyright 2020 Elsevier B.V., All rights reserved.; 24th European Conference on Artificial Intelligence, ECAI 2020, including 10th Conference on Prestigious Applications of Artificial Intelligence, PAIS 2020 ; Conference date: 29-08-2020 Through 08-09-2020",
year = "2020",
month = aug,
day = "24",
doi = "10.3233/FAIA200281",
language = "English (US)",
series = "Frontiers in Artificial Intelligence and Applications",
publisher = "IOS Press BV",
pages = "1690--1697",
editor = "{De Giacomo}, Giuseppe and Alejandro Catala and Bistra Dilkina and Michela Milano and Senen Barro and Alberto Bugarin and Jerome Lang",
booktitle = "ECAI 2020 - 24th European Conference on Artificial Intelligence, including 10th Conference on Prestigious Applications of Artificial Intelligence, PAIS 2020 - Proceedings",
}
@inproceedings{sculley2015,
  title={Hidden Technical Debt in Machine Learning Systems},
  author={D. Sculley and Gary Holt and D. Golovin and Eugene Davydov and Todd Phillips and D. Ebner and Vinay Chaudhary and M. Young and J. Crespo and Dan Dennison},
  booktitle={NIPS},
  year={2015}
}
@misc{steinitz2013,
    description = {Preface The intended audience of this article is someone who knows something about Machine Learning and Artifical Neural Networks (ANNs) in particular and who recalls that fitting an ANN required a technique called backpropagation. The goal of this post is to refresh the reader’s knowledge of ANNs and backpropagation and to show that the latter…},
    author = {D. Steinitz},
    year = {2013},
    month = oct,
    title = {Backpropogation is Just Steepest Descent with Automatic Differentiation | Maths, Stats \& Functional Programming},
    howpublished = \url\{https://idontgetoutmuch.wordpress.com/2013/10/13/backpropogation-is-just-steepest-descent-with-automatic-differentiation-2/},
    note = {Accessed: 2021-04-08 09:32:23}
}

@misc{maxima2020,
    description = {Maxima is a fairly complete computer algebra system written in Lisp with an emphasis on symbolic computation. It is based on DOE-MACSYMA and licensed under the GPL free software license. Its abilities include symbolic integration, 3D plotting and solving differential equations.},
    author = {Maxima},
    year = {2020},
    keywords = {Maxima, CAS, computer algebra, mathematics, Lisp, symbolic computation, MACSYMA, GPL, free software, differential equations, plotting},
    title = {Maxima, a Computer Algebra System},
    howpublished = \url\{https://maxima.sourceforge.io/},
    note = {Accessed: 2021-04-08 09:42:45}
}

@article{trott2006,
author = {Trott, Michael},
year = {2006},
month = {01},
pages = {},
title = {The Mathematica guidebook for symbolics. With DVD},
isbn = {978-0-387-95020-4},
journal = {tThe Mathematica GuideBook for Symbolics},
doi = {10.1007/0-387-28815-5}
}

@misc{achyutuni2020,
    description = {Backpropagation is fundamental to machine learning. It is a technique for computing the gradient of a function. Given there is a technique called backpropagation, one wonders if there is a technique…},
    author = {Kiran Achyutuni},
    year = {2020},
    title = {The role of automatic differentiation in machine learning | by Kiran Achyutuni | Deep Dives into Computer Science | Medium},
    howpublished = \url\{https://medium.com/deep-dives-into-computer-science/like-backpropagation-is-there-forward-propagation-as-well-fedb22828b36},
    note = {Accessed: 2021-04-08 09:56:31}
}

@article{baydin2015,
  author    = {Atilim Gunes Baydin and
               Barak A. Pearlmutter and
               Alexey Andreyevich Radul},
  title     = {Automatic differentiation in machine learning: a survey},
  journal   = {CoRR},
  volume    = {abs/1502.05767},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.05767},
  archivePrefix = {arXiv},
  eprint    = {1502.05767},
  timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BaydinPR15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
